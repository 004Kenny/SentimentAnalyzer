{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# NLTK / VADER\n",
    "import nltk\n",
    "try:\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "except Exception:\n",
    "    nltk.download('vader_lexicon')\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    accuracy_score, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "SAVE_RAW_TEXT = False   # PHI-safe\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def load_tsv(path):\n",
    "    df = pd.read_csv(path, delimiter='\\t', header=None)\n",
    "    if df.shape[1] < 2:\n",
    "        raise ValueError(f\"{path}: expected at least 2 columns (text + label)\")\n",
    "    df = df[[df.columns[0], df.columns[-1]]].copy()\n",
    "    df.columns = ['Text', 'Sentiments']\n",
    "    df['Sentiments'] = pd.to_numeric(df['Sentiments'], errors='coerce').fillna(0).astype(int).clip(0,1)\n",
    "    return df\n",
    "\n",
    "def summarize_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p_pos, r_pos, f1_pos, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "    p_m, r_m, f1_m, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision_pos': p_pos,\n",
    "        'recall_pos': r_pos,\n",
    "        'f1_pos': f1_pos,\n",
    "        'precision_macro': p_m,\n",
    "        'recall_macro': r_m,\n",
    "        'f1_macro': f1_m\n",
    "    }\n",
    "\n",
    "def plot_confusion(y_true, y_pred, title, save_path=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative','Positive'])\n",
    "    plt.figure(figsize=(5,4))\n",
    "    disp.plot(values_format='d')\n",
    "    plt.title(title)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "def print_class_style_header(df):\n",
    "    print(\"\\n RAW SENTIMENTS\")\n",
    "    print(df.head().to_string(index=True))\n",
    "    print(\"\\n Data dimesnion = \", df.shape)\n",
    "\n",
    "def print_class_style_quantitative(df_like):\n",
    "    print(\"\\n QUANTITATIVE RESULTS\")\n",
    "    print(df_like.head().to_string(index=True))\n",
    "    print(\"\\n DESCRIPTIVE STATISTICS\")\n",
    "    cols = [c for c in ['Polarity_score','subjectivity_score','Predicted_Label'] if c in df_like.columns]\n",
    "    print(df_like[cols].describe())\n",
    "\n",
    "\n",
    "def predict_textblob(texts):\n",
    "    polarity = []\n",
    "    subjectivity = []\n",
    "    for t in texts:\n",
    "        tb = TextBlob(str(t))\n",
    "        polarity.append(tb.sentiment.polarity)\n",
    "        subjectivity.append(tb.sentiment.subjectivity)\n",
    "    pred = (np.array(polarity) > 0).astype(int)\n",
    "    return {'polarity': np.array(polarity), 'subjectivity': np.array(subjectivity), 'pred': pred}\n",
    "\n",
    "def predict_vader_full(texts):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    comp, neu = [], []\n",
    "    for t in texts:\n",
    "        s = sid.polarity_scores(str(t))\n",
    "        comp.append(s['compound'])\n",
    "        neu.append(s['neu'])\n",
    "    pred = (np.array(comp) > 0).astype(int)\n",
    "    # subjectivity proxy = 1 - neu\n",
    "    subj_proxy = (1 - np.array(neu)).clip(0,1)\n",
    "    return {'compound': np.array(comp), 'neu': np.array(neu), 'subj_proxy': subj_proxy, 'pred': pred}\n",
    "\n",
    "\n",
    "def evaluate_textblob_only(dataset_path, out_dir=OUT_DIR, dataset_name=None, make_scatter=True):\n",
    "    ensure_dir(out_dir)\n",
    "    if dataset_name is None:\n",
    "        dataset_name = Path(dataset_path).stem\n",
    "\n",
    "    df = load_tsv(dataset_path)\n",
    "    texts = df['Text'].tolist()\n",
    "    y_true = df['Sentiments'].to_numpy()\n",
    "\n",
    "    print(f\"\\n================ TextBlob Dataset: {dataset_name} ================\")\n",
    "    print_class_style_header(df)\n",
    "\n",
    "    tb = predict_textblob(texts)\n",
    "    tb_metrics = summarize_metrics(y_true, tb['pred'])\n",
    "\n",
    "    tb_df = pd.DataFrame({\n",
    "        'Polarity_score': tb['polarity'],\n",
    "        'subjectivity_score': tb['subjectivity'],\n",
    "        'Predicted_Label': tb['pred']\n",
    "    })\n",
    "\n",
    "    print(\"\\n--- TextBlob (default) ---\")\n",
    "    print_class_style_quantitative(tb_df)\n",
    "\n",
    "    tb_pred_csv = os.path.join(out_dir, f\"{dataset_name}_textblob_predictions.csv\")\n",
    "    tb_save = df.copy()\n",
    "    tb_save['TB_polarity'] = tb['polarity']\n",
    "    tb_save['TB_subjectivity'] = tb['subjectivity']\n",
    "    tb_save['TB_pred_default'] = tb['pred']\n",
    "    tb_save = tb_save if SAVE_RAW_TEXT else tb_save.drop(columns=['Text'])\n",
    "    tb_save.to_csv(tb_pred_csv, index=False)\n",
    "\n",
    "    # Styled scatter (like your image)\n",
    "    if make_scatter:\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.scatter(tb['polarity'], tb['subjectivity'], alpha=0.6)\n",
    "        plt.axvline(0, linestyle='--', linewidth=1)\n",
    "        plt.axhline(0.5, linestyle='--', linewidth=1)\n",
    "        plt.xlabel('Polarity (-1 to 1)')\n",
    "        plt.ylabel('Subjectivity (0 to 1)')\n",
    "        plt.title(f'TextBlob Sentiment Distribution — {dataset_name}')\n",
    "        plt.savefig(os.path.join(out_dir, f\"{dataset_name}_textblob_scatter.png\"), bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    plot_confusion(y_true, tb['pred'], f'TextBlob (default) — {dataset_name}',\n",
    "                   save_path=os.path.join(out_dir, f\"{dataset_name}_textblob_cm_default.png\"))\n",
    "\n",
    "    return {'dataset': dataset_name, 'model': 'TextBlob_default', **tb_metrics,\n",
    "            'scores_x': tb['polarity'], 'scores_y': tb['subjectivity']}\n",
    "\n",
    "\n",
    "def evaluate_vader_only(dataset_path, out_dir=OUT_DIR, dataset_name=None, make_scatter=True):\n",
    "    ensure_dir(out_dir)\n",
    "    if dataset_name is None:\n",
    "        dataset_name = Path(dataset_path).stem\n",
    "\n",
    "    df = load_tsv(dataset_path)\n",
    "    texts = df['Text'].tolist()\n",
    "    y_true = df['Sentiments'].to_numpy()\n",
    "\n",
    "    print(f\"\\n================ VADER Dataset: {dataset_name} ================\")\n",
    "    print_class_style_header(df)\n",
    "\n",
    "    va = predict_vader_full(texts)\n",
    "    va_metrics = summarize_metrics(y_true, va['pred'])\n",
    "\n",
    "    va_df = pd.DataFrame({\n",
    "        'Polarity_score': va['compound'],        # x-axis value\n",
    "        'subjectivity_score': va['subj_proxy'],  # y-axis proxy\n",
    "        'Predicted_Label': va['pred']\n",
    "    })\n",
    "\n",
    "    print(\"\\n--- VADER (default) ---\")\n",
    "    print_class_style_quantitative(va_df)\n",
    "\n",
    "    va_pred_csv = os.path.join(out_dir, f\"{dataset_name}_vader_predictions.csv\")\n",
    "    va_save = df.copy()\n",
    "    va_save['VADER_compound'] = va['compound']\n",
    "    va_save['VADER_neu'] = va['neu']\n",
    "    va_save['VADER_subj_proxy'] = va['subj_proxy']\n",
    "    va_save['VADER_pred_default'] = va['pred']\n",
    "    va_save = va_save if SAVE_RAW_TEXT else va_save.drop(columns=['Text'])\n",
    "    va_save.to_csv(va_pred_csv, index=False)\n",
    "\n",
    "    plot_confusion(y_true, va['pred'], f'VADER (default) — {dataset_name}',\n",
    "                   save_path=os.path.join(out_dir, f\"{dataset_name}_vader_cm_default.png\"))\n",
    "\n",
    "    # Styled VADER scatter with same axes & guides\n",
    "    if make_scatter:\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.scatter(va['compound'], va['subj_proxy'], alpha=0.6)\n",
    "        plt.axvline(0, linestyle='--', linewidth=1)\n",
    "        plt.axhline(0.5, linestyle='--', linewidth=1)\n",
    "        plt.xlabel('Polarity (-1 to 1)')     # to match style\n",
    "        plt.ylabel('Subjectivity (0 to 1)')  # proxy: 1 - neutral\n",
    "        plt.title(f'VADER Sentiment Distribution — {dataset_name}')\n",
    "        plt.savefig(os.path.join(out_dir, f\"{dataset_name}_vader_scatter.png\"), bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "    return {'dataset': dataset_name, 'model': 'VADER_default', **va_metrics,\n",
    "            'scores_x': va['compound'], 'scores_y': va['subj_proxy']}\n",
    "\n",
    "\n",
    "def combined_scatter(tb_x, tb_y, va_x, va_y, out_dir=OUT_DIR, filename=\"combined_scatter_models_matched_axes.png\"):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.scatter(tb_x, tb_y, alpha=0.6, marker='x', label='TextBlob (polarity, subjectivity)')\n",
    "    plt.scatter(va_x, va_y, alpha=0.6, marker='o', label='VADER (compound, 1 - neutral)')\n",
    "    plt.axvline(0, linestyle='--', linewidth=1)\n",
    "    plt.axhline(0.5, linestyle='--', linewidth=1)\n",
    "    plt.xlabel('Polarity (-1 to 1)')\n",
    "    plt.ylabel('Subjectivity (0 to 1)')\n",
    "    plt.title('Model Comparison — Same Axes (TextBlob vs VADER)')\n",
    "    plt.legend()\n",
    "    out_path = os.path.join(out_dir, filename)\n",
    "    plt.savefig(out_path, bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# Configure datasets\n",
    "TEXTBLOB_DATASET = \"health_labelled.txt\"          # TextBlob uses this\n",
    "VADER_DATASET    = \"vader_labelled.txt\"    # VADER uses this\n",
    "\n",
    "tb_result = evaluate_textblob_only(TEXTBLOB_DATASET)\n",
    "va_result = evaluate_vader_only(VADER_DATASET)\n",
    "\n",
    "# Combined scatter with matched axes\n",
    "combined_path = combined_scatter(tb_result['scores_x'], tb_result['scores_y'],\n",
    "                                 va_result['scores_x'], va_result['scores_y'])\n",
    "print(f\"Combined scatter saved to: {combined_path}\")\n",
    "\n",
    "# Summary table\n",
    "summary_df = pd.DataFrame([\n",
    "    {k: v for k, v in tb_result.items() if k not in ('scores_x','scores_y')},\n",
    "    {k: v for k, v in va_result.items() if k not in ('scores_x','scores_y')}\n",
    "])\n",
    "summary_csv = os.path.join(OUT_DIR, \"summary_custom_datasets_matched_axes.csv\")\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "print(\"\\n=== Summary (Custom Datasets per Model) ===\")\n",
    "print(summary_df)\n",
    "print(f\"\\nSaved: {summary_csv}\")\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(summary_df)\n",
    "except Exception:\n",
    "    pass\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
